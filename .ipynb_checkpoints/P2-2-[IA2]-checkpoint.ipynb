{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training texts: 11314\n",
      "Test texts: 7532\n"
     ]
    }
   ],
   "source": [
    "train_data = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print(\"Training texts:\", len(train_data.data))\n",
    "print(\"Test texts:\", len(test_data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos el fichero a una lista (una línea por item)\n",
    "with open('words.txt') as f:\n",
    "    dictionary = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary= False, vocabulary=dictionary, stop_words='english', ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4,  8, 19,  4, 14,  6,  0,  1,\n",
       "        7, 12,  5,  0, 10,  6,  2,  4,  1, 12,  9, 15,  7,  6, 13, 12, 17,\n",
       "       18, 10,  8, 11,  8, 16,  9,  4,  3,  9,  9,  4,  4,  8, 12, 14,  5,\n",
       "       15,  2, 13, 17, 11,  7, 10,  2, 14, 12,  5,  4,  6,  7,  0, 11, 16,\n",
       "        0,  6, 17,  7, 12,  7,  3, 12, 11,  7,  2,  2,  0, 16,  1,  2,  7,\n",
       "        3,  2,  1, 10, 12, 12, 17, 12,  2,  8,  8, 18,  5,  0,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es para saber que hay suficientes elementos de cada tipo, por lo que podremos hacer selecciones aleatorias hasta tener 3 de cada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 480,\n",
       " 1: 584,\n",
       " 2: 591,\n",
       " 3: 590,\n",
       " 4: 578,\n",
       " 5: 593,\n",
       " 6: 585,\n",
       " 7: 594,\n",
       " 8: 598,\n",
       " 9: 597,\n",
       " 10: 600,\n",
       " 11: 595,\n",
       " 12: 591,\n",
       " 13: 594,\n",
       " 14: 593,\n",
       " 15: 599,\n",
       " 16: 546,\n",
       " 17: 564,\n",
       " 18: 465,\n",
       " 19: 377}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(train_data.target, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data:\n",
    "        print('Mensaje', index, ':', data[index])\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector_data = vectorizer.fit_transform(train_data.data)\n",
    "test_vector_data = vectorizer.fit_transform(test_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4151)\t1\n",
      "  (0, 52160)\t1\n",
      "  (0, 53807)\t1\n",
      "  (0, 56907)\t1\n",
      "  (0, 78575)\t1\n",
      "  (0, 112523)\t1\n",
      "  (0, 112565)\t1\n",
      "  (0, 124009)\t1\n",
      "  (0, 124372)\t1\n",
      "  (0, 149051)\t1\n",
      "  (0, 177802)\t1\n",
      "  (0, 184493)\t1\n",
      "  (0, 185287)\t1\n",
      "  (0, 190955)\t1\n",
      "  (0, 208543)\t1\n",
      "  (0, 213043)\t1\n",
      "  (0, 218699)\t1\n",
      "  (0, 221810)\t1\n",
      "  (0, 221819)\t1\n",
      "  (0, 225798)\t1\n",
      "  (0, 242690)\t1\n",
      "  (0, 251793)\t1\n",
      "  (0, 271493)\t1\n",
      "  (0, 306014)\t1\n",
      "  (0, 314710)\t1\n",
      "  :\t:\n",
      "  (11313, 12051)\t1\n",
      "  (11313, 31047)\t1\n",
      "  (11313, 110477)\t1\n",
      "  (11313, 124009)\t1\n",
      "  (11313, 163078)\t1\n",
      "  (11313, 170696)\t1\n",
      "  (11313, 192874)\t1\n",
      "  (11313, 217697)\t1\n",
      "  (11313, 218699)\t1\n",
      "  (11313, 239824)\t1\n",
      "  (11313, 265072)\t2\n",
      "  (11313, 271493)\t1\n",
      "  (11313, 306014)\t1\n",
      "  (11313, 340787)\t1\n",
      "  (11313, 359935)\t1\n",
      "  (11313, 360545)\t1\n",
      "  (11313, 365530)\t1\n",
      "  (11313, 385115)\t2\n",
      "  (11313, 389038)\t1\n",
      "  (11313, 391937)\t1\n",
      "  (11313, 398618)\t1\n",
      "  (11313, 400462)\t1\n",
      "  (11313, 410906)\t1\n",
      "  (11313, 413140)\t1\n",
      "  (11313, 419956)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number\n"
     ]
    }
   ],
   "source": [
    "print(feature_names[265072])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje 1 vectorizado: ['acceleration' 'adapters' 'answered' 'article' 'attained' 'brave' 'cards'\n",
      " 'clock' 'days' 'detailing' 'disk' 'especially' 'experiences' 'final'\n",
      " 'floppy' 'floppies' 'functionality' 'heat' 'hour' 'keywords' 'knowledge'\n",
      " 'lines' 'message' 'network' 'number' 'organization' 'oscillator'\n",
      " 'posting' 'procedure' 'rated' 'reports' 'requested' 'send' 'shared'\n",
      " 'sinks' 'souls' 'speed' 'subject' 'summary' 'summarizing' 'thanks'\n",
      " 'upgrade' 'upgraded' 'usage'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_terms(feature_names, None, train_vector_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_vector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a elegir 3 mensajes de cada tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.target[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([20, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][2] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "print(np.cumsum(a[0])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 10. 15.]\n"
     ]
    }
   ],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedIndex = np.zeros([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(selectedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-111-72dbd1ee72f7>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-111-72dbd1ee72f7>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    if(se)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def select_index(num_samples, test_data, num_clases):\n",
    "    selected = np.zeros([num_classes, num_samples])\n",
    "    selectedIndex = np.zeros([num_classes])\n",
    "    \n",
    "    while np.cumsum(selectedIndex)[-1] < num_classes*num_samples:\n",
    "        index = random.randint(0, len(test_data.target))\n",
    "        category = test_data.taget[index]\n",
    "        \n",
    "        if(selectedIndex[cat])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while the last element of the sum of all the previous elements (which is the sum of the total selectec texts) \n",
    "#    is less than the desired amount, it will keep choosing candidates\n",
    "\n",
    "selected = [0]*len(test_data.target_names)\n",
    "\n",
    "number_samples = 3\n",
    "\n",
    "selected_index = [0]*len(test_data.target_names)*number_samples\n",
    "\n",
    "while (np.cumsum(selected)[-1] < len(selected)*number_samples):\n",
    "\n",
    "    #Indice aleatorio de la lista de mensajes\n",
    "    index = random.randint(0, len(test_data.target))\n",
    "    #cat = numero de la categoria a la que pertenece el índice elegido\n",
    "    cat = test_data.target[index]\n",
    "    #Comprobamos que no haya ya 3 elementos de la categoría a la que pertenezca el index y lo añadimos a la cuenta y a la lista de índices\n",
    "    #La lista de índices estará ordenada por categorías\n",
    "    if(selected[cat] < 3):\n",
    "        selected_index[cat*number_samples + selected[cat]] = index\n",
    "        selected[cat] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(selected)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual merece más la pena ponerlo en una matriz de N*M siendo N el número de elementos por cada clase y M el número de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95,\n",
       " 3112,\n",
       " 4853,\n",
       " 3495,\n",
       " 4330,\n",
       " 7337,\n",
       " 3467,\n",
       " 7041,\n",
       " 6012,\n",
       " 4711,\n",
       " 7094,\n",
       " 3095,\n",
       " 6972,\n",
       " 6319,\n",
       " 6646,\n",
       " 3922,\n",
       " 1933,\n",
       " 2337,\n",
       " 5298,\n",
       " 3106,\n",
       " 1437,\n",
       " 2547,\n",
       " 3791,\n",
       " 4832,\n",
       " 2512,\n",
       " 1291,\n",
       " 6637,\n",
       " 1350,\n",
       " 6346,\n",
       " 1700,\n",
       " 601,\n",
       " 7034,\n",
       " 2616,\n",
       " 5923,\n",
       " 3309,\n",
       " 1215,\n",
       " 7507,\n",
       " 4569,\n",
       " 6152,\n",
       " 4630,\n",
       " 5793,\n",
       " 2137,\n",
       " 7112,\n",
       " 3732,\n",
       " 1621,\n",
       " 6786,\n",
       " 3761,\n",
       " 6729,\n",
       " 4675,\n",
       " 4772,\n",
       " 877,\n",
       " 7101,\n",
       " 1318,\n",
       " 6138,\n",
       " 1675,\n",
       " 6871,\n",
       " 4342,\n",
       " 4635,\n",
       " 2300,\n",
       " 6690]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_vector_data[2252])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = selected_index[0:3]\n",
    "#print(indices)\n",
    "#out1 = train_vector_data.tocsc()[indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosSim1 = cosine_similarity(train_vector_data[2252], train_vector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ver, entonces, lo que creo que hay que hacer es:\n",
    "\n",
    "    1) Hacer el cosine similarity para cada una de las 60 indices que hemos elegido.\n",
    "    2) Agruparlos de 3 en 3 ya que es el número de muestras que nos dicen que cojamos (ponerlo como un parámetro)\n",
    "    3) Ordenar los 20 arrays, en total cada uno tendrá (número de textos)*3 elementos\n",
    "    4) Cuando tengamos todos los elementos ordenador hacemos lo de la exhaustividad (recall, es decir de entre todos los que han dado positivo (que se parecen al texto objetivo) cuantos son realmente de la misma categoría(True Pos/(True Pos + False Neg))) entre valores de 3 y 10. Eso significa que tenemos que ver para los mejores X valores (entre 3 y 10) cuantos son de la misma categoría que la clase que estamos comparando\n",
    "    5) Hacer la media de los "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nononono a ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que piden de:  la precisión de la lista de resultados con nivel de exhaustividad 3 y 10.\n",
    "\n",
    "Lo que hay que hacer es: De los X valores que más se parezcan entre los X primeros recuperados. Por lo que símplemente es coger y decir: Si para un nivel de exhaustividad 7, cogemos los 7 elementos que más se parezcan a los textos que hemos metido, después comprobamos de esos 7 cuantos son de la clase a la que perteneces los mensajes seleccionados antes.\n",
    "\n",
    "Entonces, después cogemos esos 8 resultados (los valores de 3 a 10) y hacemos la media. Eso para cada clase.\n",
    "\n",
    "Así podemos ver cual es la clase que más parecidos tiene o algo así (?)\n",
    "\n",
    "\n",
    "Y luego hay que hacer lo mismo pero con el TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la duda que luego voy a preguntar es que si lo de exhaustivodad de nivel 5 por ejemplo, significa realmente que solo hay que coger los 5 elementos más TOP, me parece raro porque hay miles y miles y quedarse con tan pocos se me hace raro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentar hacer la movida con funciones para que quede guay y bien indicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11314)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSim1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosSim2 = cosine_similarity(train_vector_data[2251], train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosSim3 = cosine_similarity(train_vector_data[2250], train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosSim = np.concatenate((cosSim1, cosSim2, cosSim3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cosSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosSim = -np.sort(-cosSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosSimFinal = cosSim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33942,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSimFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que le metes los índices seleccionados, el número de elementos por categoría y/o  el número de categorías\n",
    "#Devuelve un array con un número de columnas igual al número de categorías y número de filas igual al\n",
    "#    (número de textos - 1)*número de elementos elegidos por categoría - 3. El - 3 es para quitar las comparaciones de los textos\n",
    "#    con ellos mismos. La lista está completamente ordenada de mayor a menor.\n",
    "\n",
    "def cosSim_calc(indexes, elem, rows, numCat = None):\n",
    "    print(indexes)\n",
    "    print(len(indexes))\n",
    "    \n",
    "    cols = int(len(indexes)/elem)\n",
    "    print(rows, cols)\n",
    "    \n",
    "    sim = [[0]*rows]*cols\n",
    "    \n",
    "    col = 0\n",
    "    tempBatch_index = []\n",
    "    #Para cada indice seleccionado hacemos la cosine_similarity\n",
    "    for index in indexes:\n",
    "        \n",
    "        #Cogemos un grupo de \"elem\" elementos, de esta manera tendremos los indices con los que vamos a trabajar a continuación\n",
    "        tempBatch_index.append(index)\n",
    "        \n",
    "        #Si ya hemos cogido los \"elem\" elementos, procedemos a usarlos\n",
    "        if(len(tempBatch_index) == 3):\n",
    "            #print(tempBatch_index)\n",
    "            #Los agrupamos por categorías\n",
    "            agg = []\n",
    "            print(col)\n",
    "            for i in range(elem):\n",
    "                cosSim = cosine_similarity(test_vector_data[tempBatch_index[i]], train_vector_data)\n",
    "                agg = np.concatenate((agg, cosSim[0]))\n",
    "                #print(-np.sort(-agg))\n",
    "                \n",
    "            #Transformamos la representación de la información a dataFrames para poder mantener tener la categoría de cada elemento\n",
    "            info = pd.DataFrame(agg, columns=['puntuacion'])\n",
    "            #juntamos los indices para que coincidan con la información del DataFrame\n",
    "            categorias = np.array([])\n",
    "            for i in range(elem):\n",
    "                categorias = np.append(categorias, train_data.target)\n",
    "            \n",
    "            info['categoria'] = categorias\n",
    "            info = info.sort_values(by='puntuacion', ascending=False)\n",
    "            #info = info[elem:]\n",
    "            sim[col] = info\n",
    "            print(max(sim[col]['puntuacion']))\n",
    "            #print(agg[:5])\n",
    "            #sim[col] = -np.sort(-agg)\n",
    "            #print(sim[col])\n",
    "            #Ahora quitamos los elementos que son =1, es decir los que se han comparado con si mismos, que ahora están en las \"elem\"\n",
    "            #    primeras posiciones\n",
    "            #sim[col] = sim[col][elem:]\n",
    "            \n",
    "            #print(sim[col][:10])\n",
    "            #print(max(sim[col]))\n",
    "            #print(tempBatch_index)\n",
    "            col+=1\n",
    "            tempBatch_index = []\n",
    "\n",
    "    \n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 3112, 4853, 3495, 4330, 7337, 3467, 7041, 6012, 4711, 7094, 3095, 6972, 6319, 6646, 3922, 1933, 2337, 5298, 3106, 1437, 2547, 3791, 4832, 2512, 1291, 6637, 1350, 6346, 1700, 601, 7034, 2616, 5923, 3309, 1215, 7507, 4569, 6152, 4630, 5793, 2137, 7112, 3732, 1621, 6786, 3761, 6729, 4675, 4772, 877, 7101, 1318, 6138, 1675, 6871, 4342, 4635, 2300, 6690]\n",
      "60\n",
      "11314 20\n",
      "0\n",
      "0.44866998231315963\n",
      "1\n",
      "0.5940885257860047\n",
      "2\n",
      "0.45939149659322087\n",
      "3\n",
      "0.6761070917156279\n",
      "4\n",
      "0.4097999809317564\n",
      "5\n",
      "0.37363235887853663\n",
      "6\n",
      "0.9697651491183022\n",
      "7\n",
      "0.4313489850488289\n",
      "8\n",
      "0.6520506636966266\n",
      "9\n",
      "0.35148175122006836\n",
      "10\n",
      "0.386333704643128\n",
      "11\n",
      "0.7498063766587063\n",
      "12\n",
      "0.7540739028638984\n",
      "13\n",
      "0.31193682406898127\n",
      "14\n",
      "0.6079476701167376\n",
      "15\n",
      "0.5892556509887895\n",
      "16\n",
      "0.4140043409440132\n",
      "17\n",
      "0.6549612691572329\n",
      "18\n",
      "0.4813299149207704\n",
      "19\n",
      "0.4542199791661352\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosSim_calc(selected_index, 3, len(train_data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33942"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cos_sim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31193682406898127\n"
     ]
    }
   ],
   "source": [
    "print(max(cos_sim[13]['puntuacion'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44866998231315963\n",
      "0.5940885257860047\n",
      "0.45939149659322087\n",
      "0.6761070917156279\n",
      "0.4097999809317564\n",
      "0.37363235887853663\n",
      "0.9697651491183022\n",
      "0.4313489850488289\n",
      "0.6520506636966266\n",
      "0.35148175122006836\n",
      "0.386333704643128\n",
      "0.7498063766587063\n",
      "0.7540739028638984\n",
      "0.31193682406898127\n",
      "0.6079476701167376\n",
      "0.5892556509887895\n",
      "0.4140043409440132\n",
      "0.6549612691572329\n",
      "0.4813299149207704\n",
      "0.4542199791661352\n"
     ]
    }
   ],
   "source": [
    "for elem in cos_sim:\n",
    "    print(max(elem['puntuacion'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora toca hacer los niveles de exhaustividad con la información bien colocadita que tenemos aquí\n",
    "\n",
    "Lo que vamos a hacer es dejar en una matriz de N*M los resultados del recall\n",
    "    Siendo N=número de clases y M=niveles de exhaustividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>puntuacion</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7359</td>\n",
       "      <td>0.594089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28033</td>\n",
       "      <td>0.521286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33710</td>\n",
       "      <td>0.440959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23669</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10907</td>\n",
       "      <td>0.424264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9412</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11458</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32040</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12855</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20726</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33942 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       puntuacion  categoria\n",
       "7359     0.594089        1.0\n",
       "28033    0.521286        1.0\n",
       "33710    0.440959        1.0\n",
       "23669    0.434975        1.0\n",
       "10907    0.424264        1.0\n",
       "...           ...        ...\n",
       "9412     0.006013       10.0\n",
       "11458    0.005246        2.0\n",
       "32040    0.005011       10.0\n",
       "12855    0.004715        2.0\n",
       "20726    0.003849       10.0\n",
       "\n",
       "[33942 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nivel: 3\n",
      "nivel: 4\n",
      "nivel: 5\n",
      "nivel: 6\n",
      "nivel: 7\n",
      "nivel: 8\n",
      "nivel: 9\n",
      "nivel: 10\n"
     ]
    }
   ],
   "source": [
    "Niveles_exhaustividad = range(3,11)\n",
    "\n",
    "MeanExhaust = [0]*len(test_data.target_names)\n",
    "\n",
    "for i in Niveles_exhaustividad:\n",
    "    print(f\"nivel: {i}\")\n",
    "    \n",
    "    for j in len(test_data.target_names):\n",
    "    \n",
    "        selected = cos_sim[j]['puntuacion'][:i].values\n",
    "        for k in len(selected):\n",
    "            if(k == )\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
